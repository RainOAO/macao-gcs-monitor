#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¾³é–€æ–°èå±€è»åœ˜èŒæ–°èç›£æ§ç³»çµ± - Email æ¨é€ç‰ˆæœ¬
è‡ªå‹•æŠ“å–ä¸€å¤©å…§æ‰€æœ‰æ–°èï¼Œæª¢æŸ¥æ¨™é¡Œå’Œå…§æ–‡æ˜¯å¦åŒ…å«è»åœ˜èŒé—œéµè©ï¼Œä¸¦é€šé Email æ¨é€
"""

import os
import sys
import json
import logging
import argparse
import time
import smtplib
import ssl
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Set, Optional
from urllib.parse import urljoin
from concurrent.futures import ThreadPoolExecutor, as_completed
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header

import requests
from bs4 import BeautifulSoup


class MacauNewsMonitorEmail:
    """æ¾³é–€æ–°èç›£æ§å™¨ - Email æ¨é€ç‰ˆæœ¬"""
    
    def __init__(self, config_file: str = "config.json"):
        """åˆå§‹åŒ–ç›£æ§å™¨"""
        self.config = self._load_config(config_file)
        self._setup_logging()
        self.sent_news = self._load_sent_news()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def _load_config(self, config_file: str) -> dict:
        """åŠ è¼‰é…ç½®æ–‡ä»¶"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"éŒ¯èª¤: é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨")
            sys.exit(1)
        except json.JSONDecodeError as e:
            print(f"éŒ¯èª¤: é…ç½®æ–‡ä»¶æ ¼å¼éŒ¯èª¤ - {e}")
            sys.exit(1)
            
    def _setup_logging(self):
        """è¨­ç½®æ—¥èªŒ"""
        log_level = getattr(logging, self.config.get('log_level', 'INFO'))
        logging.basicConfig(
            level=log_level,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('macau_news_monitor.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def _load_sent_news(self) -> Set[str]:
        """åŠ è¼‰å·²ç™¼é€çš„æ–°èè¨˜éŒ„"""
        sent_file = self.config.get('sent_news_file', 'sent_news.json')
        if os.path.exists(sent_file):
            try:
                with open(sent_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('sent_urls', []))
            except Exception as e:
                self.logger.warning(f"åŠ è¼‰å·²ç™¼é€è¨˜éŒ„å¤±æ•—: {e}")
        return set()
        
    def _save_sent_news(self):
        """ä¿å­˜å·²ç™¼é€çš„æ–°èè¨˜éŒ„"""
        sent_file = self.config.get('sent_news_file', 'sent_news.json')
        try:
            with open(sent_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'sent_urls': list(self.sent_news),
                    'last_updated': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ä¿å­˜å·²ç™¼é€è¨˜éŒ„å¤±æ•—: {e}")
    
    def fetch_page(self, page_num: int = 0) -> List[Dict[str, str]]:
        """æŠ“å–æŒ‡å®šé é¢çš„æ–°èåˆ—è¡¨"""
        news_url = self.config.get('news_url', 'https://www.gcs.gov.mo/list/zh-hans/news/')
        
        if page_num == 0:
            url = news_url
        else:
            url = f"{news_url}?0-1.0-infoContent-infoTable-nextItems&nextPage={page_num}"
        
        self.logger.debug(f"æ­£åœ¨æŠ“å–ç¬¬ {page_num + 1} é : {url}")
        
        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            response.encoding = 'utf-8'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            news_list = []
            
            news_items = soup.find_all('tr', class_='infiniteItem')
            
            for item in news_items:
                try:
                    h5 = item.find('h5')
                    if not h5:
                        continue
                    
                    title = h5.get_text(strip=True)
                    if not title:
                        continue
                    
                    link_tag = item.find('a', href=lambda x: x and '/detail/' in x)
                    if not link_tag:
                        continue
                    
                    href = link_tag.get('href', '')
                    if not href:
                        continue
                    
                    url = urljoin(news_url, href)
                    
                    if ';jsessionid=' in url:
                        url = url.split(';jsessionid=')[0]
                    
                    publish_time = None
                    time_tag = item.find('time', class_='render_timeago_css')
                    if time_tag and time_tag.get('datetime'):
                        try:
                            datetime_str = time_tag.get('datetime')
                            publish_time = datetime.fromisoformat(datetime_str.replace('+0800', '+08:00'))
                        except Exception as e:
                            self.logger.debug(f"è§£ææ—¥æœŸå¤±æ•— {datetime_str}: {e}")
                    
                    news_list.append({
                        'title': title,
                        'url': url,
                        'publish_time': publish_time,
                        'content': None
                    })
                    
                except Exception as e:
                    self.logger.warning(f"è§£ææ–°èé …å¤±æ•—: {e}")
                    continue
            
            return news_list
            
        except requests.RequestException as e:
            self.logger.error(f"æŠ“å–ç¬¬ {page_num + 1} é å¤±æ•—: {e}")
            return []
        except Exception as e:
            self.logger.error(f"è§£æç¬¬ {page_num + 1} é å¤±æ•—: {e}")
            return []
    
    def fetch_all_pages(self) -> List[Dict[str, str]]:
        """æŠ“å–å¤šé æ–°èåˆ—è¡¨ï¼Œä¸¦éæ¿¾ä¸€å¤©å…§çš„æ–°è"""
        max_pages = self.config.get('max_pages', 10)
        days_to_check = self.config.get('days_to_check', 1)
        all_news = []
        
        cutoff_time = datetime.now(timezone.utc) - timedelta(days=days_to_check)
        
        self.logger.info(f"é–‹å§‹æŠ“å–æœ€å¤š {max_pages} é æ–°èï¼ˆåªä¿ç•™ {days_to_check} å¤©å…§çš„æ–°èï¼‰...")
        
        for page in range(max_pages):
            news_list = self.fetch_page(page)
            
            if not news_list:
                self.logger.info(f"ç¬¬ {page + 1} é ç„¡æ–°èï¼Œåœæ­¢æŠ“å–")
                break
            
            old_news_count = 0
            for news in news_list:
                if news.get('publish_time'):
                    if news['publish_time'] < cutoff_time:
                        old_news_count += 1
            
            all_news.extend(news_list)
            self.logger.info(f"ç¬¬ {page + 1} é : {len(news_list)} æ¢æ–°è ({old_news_count} æ¢è¶…é {days_to_check} å¤©)")
            
            if old_news_count >= len(news_list) * 0.8:
                self.logger.info(f"ç¬¬ {page + 1} é å¤§éƒ¨åˆ†æ–°èå·²è¶…é {days_to_check} å¤©ï¼Œåœæ­¢æŠ“å–")
                break
            
            if page < max_pages - 1:
                time.sleep(1)
        
        seen = {}
        for news in all_news:
            if news['url'] not in seen:
                seen[news['url']] = news
        
        unique_news = list(seen.values())
        
        recent_news = []
        for news in unique_news:
            if news.get('publish_time'):
                if news['publish_time'] >= cutoff_time:
                    recent_news.append(news)
            else:
                recent_news.append(news)
        
        self.logger.info(f"å…±æŠ“å– {len(all_news)} æ¢æ–°èï¼Œå»é‡å¾Œ {len(unique_news)} æ¢ï¼Œ{days_to_check} å¤©å…§æ–°è {len(recent_news)} æ¢")
        
        return recent_news
    
    def fetch_article_content(self, url: str) -> str:
        """æŠ“å–å–®ç¯‡æ–°èçš„å…§æ–‡"""
        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            response.encoding = 'utf-8'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            content_parts = []
            
            paragraphs = soup.find_all('p')
            for p in paragraphs:
                text = p.get_text(strip=True)
                if len(text) > 20 and not text.startswith('è·³è‡³'):
                    content_parts.append(text)
            
            if not content_parts:
                main_content = soup.find('main') or soup.find('article') or soup.find('div', class_='content')
                if main_content:
                    content_parts.append(main_content.get_text(separator=' ', strip=True))
            
            if not content_parts:
                og_desc = soup.find('meta', property='og:description')
                if og_desc and og_desc.get('content'):
                    content_parts.append(og_desc.get('content'))
            
            content_text = ' '.join(content_parts)
            content_text = ' '.join(content_text.split())
            
            return content_text
            
        except Exception as e:
            self.logger.debug(f"æŠ“å–å…§æ–‡å¤±æ•— {url}: {e}")
            return ""
    
    def fetch_contents_concurrent(self, news_list: List[Dict]) -> List[Dict]:
        """ä½µç™¼æŠ“å–å¤šå€‹æ–°èçš„å…§æ–‡"""
        if not self.config.get('check_content', True):
            self.logger.info("é…ç½®çˆ²ä¸æª¢æŸ¥å…§æ–‡ï¼Œè·³éå…§æ–‡æŠ“å–")
            return news_list
        
        max_workers = self.config.get('concurrent_requests', 5)
        self.logger.info(f"é–‹å§‹ä½µç™¼æŠ“å– {len(news_list)} æ¢æ–°èå…§æ–‡ï¼ˆä½µç™¼æ•¸: {max_workers}ï¼‰...")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_news = {
                executor.submit(self.fetch_article_content, news['url']): news
                for news in news_list
            }
            
            completed = 0
            for future in as_completed(future_to_news):
                news = future_to_news[future]
                try:
                    content = future.result()
                    news['content'] = content
                    completed += 1
                    if completed % 10 == 0:
                        self.logger.info(f"å·²å®Œæˆ {completed}/{len(news_list)} æ¢")
                except Exception as e:
                    self.logger.warning(f"ç²å–å…§æ–‡å¤±æ•—: {e}")
                    news['content'] = ""
        
        self.logger.info(f"å…§æ–‡æŠ“å–å®Œæˆ: {len(news_list)} æ¢")
        return news_list
    
    def filter_news(self, news_list: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """éæ¿¾åŒ…å«é—œéµè©çš„æ–°èï¼ˆæ¨™é¡Œæˆ–å…§æ–‡ï¼‰"""
        keywords = self.config.get('keywords', [])
        filtered = []
        
        for news in news_list:
            text_to_search = news['title']
            if news.get('content'):
                text_to_search += ' ' + news['content']
            
            has_keyword = any(kw.lower() in text_to_search.lower() for kw in keywords)
            
            if has_keyword and news['url'] not in self.sent_news:
                filtered.append(news)
                self.logger.info(f"ç™¼ç¾ç›¸é—œæ–°è: {news['title']}")
            elif has_keyword and news['url'] in self.sent_news:
                self.logger.debug(f"æ–°èå·²ç™¼é€éï¼Œè·³é: {news['title']}")
        
        return filtered
    
    def _build_email_html(self, news_list: List[Dict[str, str]]) -> str:
        """æ§‹å»º HTML æ ¼å¼çš„éƒµä»¶å…§å®¹"""
        now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        html = f"""<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<style>
  body {{ font-family: 'Microsoft YaHei', 'Segoe UI', Arial, sans-serif; background: #f4f6f9; margin: 0; padding: 20px; }}
  .container {{ max-width: 700px; margin: 0 auto; background: #ffffff; border-radius: 10px; box-shadow: 0 2px 12px rgba(0,0,0,0.08); overflow: hidden; }}
  .header {{ background: linear-gradient(135deg, #1a73e8, #0d47a1); padding: 24px 30px; color: #ffffff; }}
  .header h1 {{ margin: 0; font-size: 22px; font-weight: 600; }}
  .header p {{ margin: 8px 0 0; font-size: 13px; opacity: 0.85; }}
  .content {{ padding: 24px 30px; }}
  .summary {{ background: #e8f0fe; border-left: 4px solid #1a73e8; padding: 12px 16px; margin-bottom: 20px; border-radius: 0 6px 6px 0; font-size: 14px; color: #1a56b8; }}
  .news-item {{ border: 1px solid #e8eaed; border-radius: 8px; padding: 16px 20px; margin-bottom: 14px; transition: box-shadow 0.2s; }}
  .news-item:hover {{ box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}
  .news-title {{ font-size: 16px; font-weight: 600; color: #202124; margin: 0 0 8px; }}
  .news-title a {{ color: #1a73e8; text-decoration: none; }}
  .news-title a:hover {{ text-decoration: underline; }}
  .news-preview {{ font-size: 13px; color: #5f6368; line-height: 1.6; margin: 0; }}
  .news-time {{ font-size: 12px; color: #9aa0a6; margin-top: 8px; }}
  .footer {{ padding: 16px 30px; background: #f8f9fa; border-top: 1px solid #e8eaed; text-align: center; font-size: 12px; color: #9aa0a6; }}
  .badge {{ display: inline-block; background: #e8f0fe; color: #1a73e8; padding: 2px 8px; border-radius: 4px; font-size: 12px; font-weight: 500; margin-left: 8px; }}
</style>
</head>
<body>
<div class="container">
  <div class="header">
    <h1>ğŸ”” æ¾³é–€æ–°èå±€ â€” è»åœ˜èŒç›¸é—œæ–°è</h1>
    <p>ç›£æ§æ™‚é–“: {now}</p>
  </div>
  <div class="content">
    <div class="summary">
      å…±ç™¼ç¾ <strong>{len(news_list)}</strong> æ¢ç›¸é—œæ–°è
    </div>
"""
        
        for i, news in enumerate(news_list, 1):
            content_preview = ""
            if news.get('content'):
                content_preview = news['content'][:300]
                if len(news['content']) > 300:
                    content_preview += "..."
            
            publish_time_str = ""
            if news.get('publish_time'):
                publish_time_str = news['publish_time'].strftime('%Y-%m-%d %H:%M')
            
            html += f"""
    <div class="news-item">
      <p class="news-title">
        {i}. <a href="{news['url']}" target="_blank">{news['title']}</a>
        <span class="badge">è»åœ˜èŒ</span>
      </p>
      {"<p class='news-preview'>" + content_preview + "</p>" if content_preview else ""}
      {"<p class='news-time'>ğŸ“… " + publish_time_str + "</p>" if publish_time_str else ""}
    </div>
"""
        
        html += """
  </div>
  <div class="footer">
    æ­¤éƒµä»¶ç”±æ¾³é–€æ–°èå±€è»åœ˜èŒæ–°èç›£æ§ç³»çµ±è‡ªå‹•ç™¼é€ Â· æ•¸æ“šä¾†æº: <a href="https://www.gcs.gov.mo" style="color:#1a73e8;">æ¾³é–€æ–°èå±€</a>
  </div>
</div>
</body>
</html>
"""
        return html
    
    def send_email(self, news_list: List[Dict[str, str]]) -> bool:
        """é€šé Email ç™¼é€æ–°èé€šçŸ¥"""
        if not news_list:
            self.logger.info("æ²’æœ‰éœ€è¦ç™¼é€çš„æ–°è")
            return True
        
        # è®€å– SMTP é…ç½®
        smtp_server = self.config.get('smtp_server', 'smtp-mail.outlook.com')
        smtp_port = self.config.get('smtp_port', 587)
        smtp_use_ssl = self.config.get('smtp_use_ssl', False)
        smtp_username = self.config.get('smtp_username', '')
        smtp_password = self.config.get('smtp_password', '')
        email_from = self.config.get('email_from', smtp_username)
        email_to = self.config.get('email_to', [])
        subject_prefix = self.config.get('email_subject_prefix', 'ã€æ¾³é–€æ–°èç›£æ§ã€‘')
        
        if not smtp_username or not smtp_password:
            self.logger.error("SMTP ç”¨æˆ¶åæˆ–å¯†ç¢¼æœªé…ç½®ï¼Œè«‹åœ¨ config.json ä¸­è¨­ç½®")
            return False
        
        if not email_to:
            self.logger.error("æ”¶ä»¶äººæœªé…ç½®ï¼Œè«‹åœ¨ config.json ä¸­è¨­ç½® email_to")
            return False
        
        # ç¢ºä¿ email_to æ˜¯åˆ—è¡¨
        if isinstance(email_to, str):
            email_to = [email_to]
        
        # æ§‹å»ºéƒµä»¶
        subject = f"{subject_prefix} ç™¼ç¾ {len(news_list)} æ¢è»åœ˜èŒç›¸é—œæ–°è"
        html_content = self._build_email_html(news_list)
        
        msg = MIMEMultipart('alternative')
        msg['From'] = email_from
        msg['To'] = ', '.join(email_to)
        msg['Subject'] = Header(subject, 'utf-8')
        
        # ç´”æ–‡æœ¬å‚™ç”¨å…§å®¹
        text_content = f"æ¾³é–€æ–°èå±€è»åœ˜èŒæ–°èç›£æ§\n\nå…±ç™¼ç¾ {len(news_list)} æ¢ç›¸é—œæ–°è:\n\n"
        for i, news in enumerate(news_list, 1):
            text_content += f"{i}. {news['title']}\n   éˆæ¥: {news['url']}\n\n"
        
        msg.attach(MIMEText(text_content, 'plain', 'utf-8'))
        msg.attach(MIMEText(html_content, 'html', 'utf-8'))
        
        # ç™¼é€éƒµä»¶
        try:
            if smtp_use_ssl:
                # SSL é€£æ¥ï¼ˆç«¯å£ 465ï¼‰
                context = ssl.create_default_context()
                with smtplib.SMTP_SSL(smtp_server, smtp_port, context=context, timeout=30) as server:
                    server.login(smtp_username, smtp_password)
                    server.sendmail(email_from, email_to, msg.as_string())
            else:
                # TLS é€£æ¥ï¼ˆç«¯å£ 587ï¼‰
                with smtplib.SMTP(smtp_server, smtp_port, timeout=30) as server:
                    server.ehlo()
                    server.starttls()
                    server.ehlo()
                    server.login(smtp_username, smtp_password)
                    server.sendmail(email_from, email_to, msg.as_string())
            
            self.logger.info(f"éƒµä»¶ç™¼é€æˆåŠŸ! æ”¶ä»¶äºº: {', '.join(email_to)}")
            
            # æ¨™è¨˜çˆ²å·²ç™¼é€
            for news in news_list:
                self.sent_news.add(news['url'])
            self._save_sent_news()
            
            return True
            
        except smtplib.SMTPAuthenticationError as e:
            self.logger.error(f"SMTP èªè­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç”¨æˆ¶åå’Œå¯†ç¢¼: {e}")
            self.logger.error("æç¤º: Outlook å¯èƒ½éœ€è¦ä½¿ç”¨æ‡‰ç”¨å°ˆç”¨å¯†ç¢¼")
            return False
        except smtplib.SMTPException as e:
            self.logger.error(f"SMTP ç™¼é€å¤±æ•—: {e}")
            return False
        except Exception as e:
            self.logger.error(f"éƒµä»¶ç™¼é€å¤±æ•—: {e}")
            return False
    
    def run(self, test_mode: bool = False):
        """é‹è¡Œç›£æ§"""
        self.logger.info("=" * 80)
        self.logger.info("æ¾³é–€æ–°èå±€è»åœ˜èŒç›£æ§ç³»çµ± (Emailç‰ˆ) - é–‹å§‹é‹è¡Œ")
        self.logger.info("=" * 80)
        
        # 1. æŠ“å–å¤šé æ–°èåˆ—è¡¨
        news_list = self.fetch_all_pages()
        if not news_list:
            self.logger.warning("æœªèƒ½ç²å–æ–°èåˆ—è¡¨")
            return
        
        # 2. æŠ“å–æ–°èå…§æ–‡ï¼ˆå¦‚æœé…ç½®å•“ç”¨ï¼‰
        if self.config.get('check_content', True):
            news_list = self.fetch_contents_concurrent(news_list)
        
        # 3. éæ¿¾ç›¸é—œæ–°è
        filtered_news = self.filter_news(news_list)
        
        # æ¸¬è©¦æ¨¡å¼ï¼šåªé¡¯ç¤ºçµæœ
        if test_mode:
            self.logger.info(f"\n{'='*80}")
            self.logger.info("æ¸¬è©¦æ¨¡å¼ - æŠ“å–çµæœ:")
            self.logger.info(f"ç¸½æ–°èæ•¸: {len(news_list)}")
            self.logger.info(f"ç›¸é—œæ–°èæ•¸: {len(filtered_news)}")
            if filtered_news:
                self.logger.info("\nç›¸é—œæ–°èåˆ—è¡¨:")
                for i, news in enumerate(filtered_news, 1):
                    self.logger.info(f"{i}. {news['title']}")
                    self.logger.info(f"   éˆæ¥: {news['url']}")
                    if news.get('content'):
                        preview = news['content'][:100]
                        self.logger.info(f"   é è¦½: {preview}...")
                    self.logger.info("")
            else:
                self.logger.info("æœªç™¼ç¾åŒ…å«é—œéµè©çš„æ–°è")
            self.logger.info(f"{'='*80}\n")
            self.logger.info("ï¼ˆæ¸¬è©¦æ¨¡å¼ä¸æœƒç™¼é€éƒµä»¶ï¼‰")
            return
        
        # æ­£å¼æ¨¡å¼ï¼šç™¼é€éƒµä»¶
        if filtered_news:
            self.send_email(filtered_news)
            self.logger.info(f"è™•ç†å®Œæˆï¼Œå…±ç™¼é€ {len(filtered_news)} æ¢æ–°è")
        else:
            self.logger.info("æœªç™¼ç¾æ–°çš„ç›¸é—œæ–°è")
            
        self.logger.info("=" * 80)


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='æ¾³é–€æ–°èå±€è»åœ˜èŒæ–°èç›£æ§ç³»çµ± (Emailç‰ˆ)')
    parser.add_argument('--test', action='store_true', help='æ¸¬è©¦æ¨¡å¼ï¼Œåªé¡¯ç¤ºçµæœä¸ç™¼é€éƒµä»¶')
    parser.add_argument('--config', default='config.json', help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    
    args = parser.parse_args()
    
    try:
        monitor = MacauNewsMonitorEmail(config_file=args.config)
        monitor.run(test_mode=args.test)
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²ä¸­æ–·")
    except Exception as e:
        print(f"ç¨‹åºé‹è¡ŒéŒ¯èª¤: {e}")
        logging.exception("è©³ç´°éŒ¯èª¤ä¿¡æ¯:")
        sys.exit(1)


if __name__ == '__main__':
    main()
